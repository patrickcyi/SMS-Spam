{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a78549649effa1858818cefd9f614338590f14c"
   },
   "source": [
    "# spam\n",
    "https://www.kaggle.com/uciml/sms-spam-collection-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d6b1ab40-34da-4645-98c4-4b61c97895f6",
    "_uuid": "0259bd59e4fad41ffd78aa5a510a83ef07daab7f",
    "collapsed": true
   },
   "source": [
    "拿到数据首先读入拿到数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "a89760f4-9075-42be-b4c4-c8c87d175c88",
    "_uuid": "4429a082ddabcb23261daec29ee1ae9e68ba2a2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"../input/\"\n",
    "df = pd.read_csv(data_dir + '/spam.csv', encoding='latin-1')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.v2,\n",
    "    df.v1, \n",
    "    test_size=0.2, \n",
    "    random_state=0)  \n",
    "\n",
    "\n",
    "\n",
    "df.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11706"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GetVocabulary(data):\n",
    "    vocab_dict={}\n",
    "    word_id=0\n",
    "    for document in data:\n",
    "        words=document.split()\n",
    "        for word in words:\n",
    "            word=word.lower()\n",
    "            if word not in vocab_dict:\n",
    "                vocab_dict[word]=word_id\n",
    "                word_id+=1\n",
    "    return vocab_dict\n",
    "\n",
    "vocab=GetVocabulary(X_train)\n",
    "vocab.get('ok')\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "db14dd202a4cb2bab6306d14e3acd2cb151f1260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. ... 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert document to vector\n",
    "def document2vector(vocab,document):\n",
    "    word_vector=np.zeros(len(vocab))\n",
    "    words=document.split()\n",
    "    not_in_vocab=0\n",
    "    for word in words:\n",
    "        word=word.lower()\n",
    "        if word in vocab:\n",
    "            word_vector[vocab[word]]+=1\n",
    "        else:\n",
    "            not_in_vocab+=1\n",
    "    return word_vector, not_in_vocab\n",
    "            \n",
    "word_vector2,not_in_cab=document2vector(vocab,'here it is')\n",
    "print(word_vector2)\n",
    "vocab.get('is')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457\n",
      "11706\n",
      "4457\n",
      "ham\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "spam\n",
      "22.0\n"
     ]
    }
   ],
   "source": [
    "# change to vector\n",
    "Xtrain_vector=[]\n",
    "for document in X_train.values:\n",
    "    word_vector,not_in_vocab=document2vector(vocab, document)\n",
    "    Xtrain_vector.append(word_vector)\n",
    "    \n",
    "    \n",
    "print(len(Xtrain_vector))\n",
    "print(len(Xtrain_vector[7])) \n",
    "print(len(y_train))\n",
    "print(y_train[3])\n",
    "print(Xtrain_vector[6])\n",
    "print(y_train[8])\n",
    "\n",
    "print(Xtrain_vector[8].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.13967219993589897 -2.0374804160946445 4457\n"
     ]
    }
   ],
   "source": [
    "y_train2=pd.DataFrame(y_train)\n",
    "y_train2.head()\n",
    "ham_number,spam_number= y_train2.groupby('v1').size()\n",
    "p_ham=np.log(ham_number/(ham_number+spam_number))\n",
    "p_spam=np.log(spam_number/(ham_number+spam_number))\n",
    "print(p_ham,p_spam,y_train.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457\n",
      "11706\n",
      "[1. 1. 2. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def NaiveBayes(Xtrain_vector,y_train):\n",
    "    num_docs=len(Xtrain_vector)\n",
    "    print(num_docs)\n",
    "    num_words=len(Xtrain_vector[0])\n",
    "    print(num_words)\n",
    "    \n",
    "    ham_word_counter=np.ones(num_words)\n",
    "    spam_word_counter=np.ones(num_words)\n",
    "    \n",
    "    total_ham_word_counter=0\n",
    "    total_spam_word_counter=0\n",
    "    print(Xtrain_vector[0])\n",
    "    \n",
    "    for i in range(num_docs):\n",
    "        \n",
    "        if y_train[i]=='ham':\n",
    "            total_ham_word_counter+=sum(Xtrain_vector[i])\n",
    "            ham_word_counter+=Xtrain_vector[i]\n",
    "        \n",
    "        else:\n",
    "            total_spam_word_counter+=sum(Xtrain_vector[i])\n",
    "            spam_word_counter+=Xtrain_vector[i]\n",
    "            \n",
    "            \n",
    "    p_spam_vector=np.log(spam_word_counter/(total_spam_word_counter+num_words))\n",
    "    p_ham_vector=np.log(ham_word_counter/(total_ham_word_counter+num_words))\n",
    "\n",
    "    return p_spam_vector, p_ham_vector,total_spam_word_counter,total_ham_word_counter,num_words\n",
    "\n",
    "\n",
    "p_spam_vector, p_ham_vector,total_spam_word_counter,total_ham_word_counter,num_words=NaiveBayes(Xtrain_vector,y_train.values)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b55b0ce4caf250c26efb4f543d257744ef8c1985"
   },
   "source": [
    "navie bayes training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "024ad891e7df647a1415d9106e42cf8951f91f6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-173.78319857384545\n",
      "-199.1828324881395\n",
      "-104.98997617691708\n",
      "-121.58339118834192\n",
      "-195.56979161410146\n",
      "-66.06061843164161\n",
      "-179.587450197175\n",
      "-112.593594975299\n",
      "-199.04761861500313\n",
      "-112.84099989124243\n",
      "-112.8818322286321\n",
      "-199.5665994778352\n",
      "-176.78744440358895\n",
      "-167.62003516475085\n",
      "-137.01464217769086\n",
      "-167.9195967745867\n",
      "-188.51849059253766\n",
      "-129.83162618663948\n",
      "-154.754203912541\n",
      "-135.6534670051044\n",
      "-202.4195662096861\n",
      "-180.73938688522387\n",
      "-197.44137734424984\n",
      "-187.90736709975795\n",
      "-177.42676975887198\n",
      "-201.9714814417114\n",
      "-178.64549764346393\n",
      "-172.41584063127036\n",
      "-49.453203592735335\n",
      "-179.38634351753063\n",
      "-139.93958206944384\n",
      "-161.43248968679876\n",
      "-178.33632745830823\n",
      "-138.48030537371426\n",
      "-215.0603664428527\n",
      "-91.52123837265654\n",
      "-148.8247238068553\n",
      "-154.3931499360932\n",
      "-190.96190806059673\n",
      "-56.081439472251205\n",
      "-123.66272928909189\n",
      "-61.36599774049385\n",
      "-211.51254548399373\n",
      "-161.1586394476845\n",
      "-56.081439472251205\n",
      "-168.13810743785461\n",
      "-114.24122181387636\n",
      "-171.4135901784928\n",
      "-198.76485554524615\n",
      "-155.42669354624687\n",
      "-175.0609959499002\n",
      "-101.37914546716453\n",
      "-190.09891331142882\n",
      "-112.78052991639687\n",
      "-190.84690188117506\n",
      "-194.13279936525947\n",
      "-196.52521022451182\n",
      "-177.45356312222742\n",
      "-56.77458665281115\n",
      "-171.73398846153236\n",
      "-175.1688257926036\n",
      "-139.49265164202657\n",
      "-170.61205867619128\n",
      "-119.3142041749459\n",
      "-202.1492911656777\n",
      "-131.38921321010884\n",
      "-113.77259263141661\n",
      "-178.27659592382747\n",
      "-121.5030416124072\n",
      "-69.44796656315246\n",
      "-156.41600372981182\n",
      "-179.38634351753063\n",
      "-187.16223694088066\n",
      "-135.6534670051044\n",
      "-179.1634508666459\n",
      "-186.1297757202563\n",
      "-123.79159629297773\n",
      "-188.4029061030202\n",
      "-167.44496025729467\n",
      "-175.88591359972457\n",
      "-65.13325702489833\n",
      "-161.92021841051624\n",
      "-178.4841107384636\n",
      "-142.43997027102293\n",
      "-192.64697803068583\n",
      "-171.49235971378982\n",
      "-163.54937330726946\n",
      "-185.30333486193067\n",
      "-84.47306769716808\n",
      "-255.6557831444984\n",
      "-192.21544341474967\n",
      "-28.07045282964745\n",
      "-185.5230422958422\n",
      "-163.26833140730878\n",
      "-196.80262201426086\n",
      "-93.5134218706281\n",
      "-134.6117898807877\n",
      "-192.66476551098108\n",
      "-188.43666376307064\n",
      "-176.8909666405759\n",
      "-180.69053984145725\n",
      "-168.13810743785461\n",
      "-169.02971486715163\n",
      "-180.71863434517624\n",
      "-171.1050026353391\n",
      "-202.7374256245158\n",
      "-205.33048558386\n",
      "-136.1642926288704\n",
      "-120.83345360915925\n",
      "-183.63475804300563\n",
      "-148.32674309521664\n",
      "-136.1642926288704\n",
      "-147.9913334804872\n",
      "-201.73458289025808\n",
      "-190.09891331142882\n",
      "-203.5223961973103\n",
      "-122.21143632957704\n",
      "-111.1185219699756\n",
      "-100.95235863783364\n",
      "-198.34669503899798\n",
      "-74.17665045950591\n",
      "-133.84065647477215\n",
      "-158.24583244895982\n",
      "-167.9195967745867\n",
      "-188.51849059253766\n",
      "-210.91763943740176\n",
      "-198.2023467066449\n",
      "-116.34438836568302\n",
      "-189.86657124412406\n",
      "-195.5362601645941\n",
      "-100.44482675562891\n",
      "-131.5435167606083\n",
      "-141.49065799539122\n",
      "-182.3002596439652\n",
      "-123.70803761002546\n",
      "-217.81096076806813\n",
      "-56.77458665281115\n",
      "-159.34159489129956\n",
      "-86.9634889886345\n",
      "-163.44671401285854\n",
      "-187.95692624452624\n",
      "-100.44482675562891\n",
      "-126.51957955276703\n",
      "-63.73825183078136\n",
      "-201.27500552164653\n",
      "-66.06061843164161\n",
      "-126.69562511590419\n",
      "-174.1368165407361\n"
     ]
    }
   ],
   "source": [
    "def prediction_bayes(X_test_vector, p_spam_vector, p_ham_vector,p_spam,p_ham,spam_smoothing, ham_smoothing):\n",
    "    spam =sum(X_test_vector* p_spam_vector) + p_spam + spam_smoothing\n",
    "    ham = sum(X_test_vector * p_ham_vector) + p_ham + ham_smoothing\n",
    "    if spam > ham:\n",
    "        print(spam)\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'ham'\n",
    "        \n",
    "\n",
    "predictions=[]\n",
    "\n",
    "for document in X_test.values:\n",
    "    X_test_vector,not_in_vocb=document2vector(vocab,document)\n",
    "    # Add smoothing for out_of_vocbulary words\n",
    "    if not_in_vocb != 0:\n",
    "        spam_smoothing = np.log(not_in_vocb/(total_spam_word_counter + num_words))\n",
    "        ham_smoothing = np.log(not_in_vocb/(total_ham_word_counter + num_words))\n",
    "    else:\n",
    "        spam_smoothing = 0\n",
    "        ham_smoothing = 0\n",
    "    ans = prediction_bayes(X_test_vector, p_spam_vector, p_ham_vector,p_spam,p_ham,spam_smoothing, ham_smoothing)\n",
    "    predictions.append(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "e4415b37-0855-49bd-8926-afe63c668268",
    "_uuid": "1d737630d3f2df2b3d28355f57cabbf594c2bf23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97847533632287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       949\n",
      "        spam       0.98      0.87      0.92       166\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.94      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "[[946   3]\n",
      " [ 21 145]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "print (accuracy_score(predictions, y_test))\n",
    "print (classification_report(y_test, predictions))\n",
    "print (confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "231f268550db0c2515b227e89d8f3510ce1d26c5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
